{
  "best_global_step": 3274,
  "best_metric": 0.3440394699573517,
  "best_model_checkpoint": "./output/sadra_qnli\\checkpoint-3274",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3274,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015271838729383017,
      "grad_norm": 0.9178212285041809,
      "learning_rate": 0.00019900223986968031,
      "loss": 0.6933,
      "step": 50
    },
    {
      "epoch": 0.030543677458766034,
      "grad_norm": 2.0344347953796387,
      "learning_rate": 0.00019798411728772145,
      "loss": 0.6161,
      "step": 100
    },
    {
      "epoch": 0.04581551618814905,
      "grad_norm": 1.2304631471633911,
      "learning_rate": 0.0001969659947057626,
      "loss": 0.5319,
      "step": 150
    },
    {
      "epoch": 0.06108735491753207,
      "grad_norm": 1.3294588327407837,
      "learning_rate": 0.00019594787212380373,
      "loss": 0.5114,
      "step": 200
    },
    {
      "epoch": 0.07635919364691508,
      "grad_norm": 1.259649634361267,
      "learning_rate": 0.00019492974954184484,
      "loss": 0.5063,
      "step": 250
    },
    {
      "epoch": 0.0916310323762981,
      "grad_norm": 1.1051944494247437,
      "learning_rate": 0.00019391162695988598,
      "loss": 0.4822,
      "step": 300
    },
    {
      "epoch": 0.10690287110568113,
      "grad_norm": 0.9993369579315186,
      "learning_rate": 0.0001928935043779271,
      "loss": 0.4806,
      "step": 350
    },
    {
      "epoch": 0.12217470983506414,
      "grad_norm": 1.3315863609313965,
      "learning_rate": 0.00019187538179596826,
      "loss": 0.4865,
      "step": 400
    },
    {
      "epoch": 0.13744654856444716,
      "grad_norm": 1.401568055152893,
      "learning_rate": 0.00019085725921400937,
      "loss": 0.4674,
      "step": 450
    },
    {
      "epoch": 0.15271838729383017,
      "grad_norm": 2.5356831550598145,
      "learning_rate": 0.0001898391366320505,
      "loss": 0.4468,
      "step": 500
    },
    {
      "epoch": 0.1679902260232132,
      "grad_norm": 1.6878989934921265,
      "learning_rate": 0.00018882101405009164,
      "loss": 0.4478,
      "step": 550
    },
    {
      "epoch": 0.1832620647525962,
      "grad_norm": 1.7168571949005127,
      "learning_rate": 0.00018780289146813278,
      "loss": 0.4429,
      "step": 600
    },
    {
      "epoch": 0.19853390348197922,
      "grad_norm": 3.2201383113861084,
      "learning_rate": 0.00018678476888617392,
      "loss": 0.4589,
      "step": 650
    },
    {
      "epoch": 0.21380574221136225,
      "grad_norm": 2.7032315731048584,
      "learning_rate": 0.00018576664630421503,
      "loss": 0.4632,
      "step": 700
    },
    {
      "epoch": 0.22907758094074526,
      "grad_norm": 1.2162076234817505,
      "learning_rate": 0.00018474852372225617,
      "loss": 0.4396,
      "step": 750
    },
    {
      "epoch": 0.24434941967012827,
      "grad_norm": 1.5145487785339355,
      "learning_rate": 0.00018373040114029728,
      "loss": 0.4463,
      "step": 800
    },
    {
      "epoch": 0.2596212583995113,
      "grad_norm": 2.891125440597534,
      "learning_rate": 0.00018271227855833845,
      "loss": 0.4334,
      "step": 850
    },
    {
      "epoch": 0.2748930971288943,
      "grad_norm": 2.310316801071167,
      "learning_rate": 0.00018169415597637956,
      "loss": 0.4509,
      "step": 900
    },
    {
      "epoch": 0.29016493585827735,
      "grad_norm": 1.3867223262786865,
      "learning_rate": 0.0001806760333944207,
      "loss": 0.4471,
      "step": 950
    },
    {
      "epoch": 0.30543677458766033,
      "grad_norm": 1.6900064945220947,
      "learning_rate": 0.00017965791081246183,
      "loss": 0.4398,
      "step": 1000
    },
    {
      "epoch": 0.32070861331704337,
      "grad_norm": 3.1907811164855957,
      "learning_rate": 0.00017863978823050294,
      "loss": 0.4256,
      "step": 1050
    },
    {
      "epoch": 0.3359804520464264,
      "grad_norm": 1.0232577323913574,
      "learning_rate": 0.0001776216656485441,
      "loss": 0.4378,
      "step": 1100
    },
    {
      "epoch": 0.3512522907758094,
      "grad_norm": 2.1753649711608887,
      "learning_rate": 0.00017660354306658522,
      "loss": 0.4198,
      "step": 1150
    },
    {
      "epoch": 0.3665241295051924,
      "grad_norm": 1.6873699426651,
      "learning_rate": 0.00017558542048462636,
      "loss": 0.4035,
      "step": 1200
    },
    {
      "epoch": 0.38179596823457546,
      "grad_norm": 1.734962821006775,
      "learning_rate": 0.00017456729790266747,
      "loss": 0.4291,
      "step": 1250
    },
    {
      "epoch": 0.39706780696395844,
      "grad_norm": 1.7158058881759644,
      "learning_rate": 0.00017354917532070864,
      "loss": 0.4377,
      "step": 1300
    },
    {
      "epoch": 0.41233964569334147,
      "grad_norm": 1.444449782371521,
      "learning_rate": 0.00017253105273874975,
      "loss": 0.4348,
      "step": 1350
    },
    {
      "epoch": 0.4276114844227245,
      "grad_norm": 2.17288875579834,
      "learning_rate": 0.00017151293015679089,
      "loss": 0.4247,
      "step": 1400
    },
    {
      "epoch": 0.4428833231521075,
      "grad_norm": 2.0537898540496826,
      "learning_rate": 0.00017049480757483202,
      "loss": 0.4455,
      "step": 1450
    },
    {
      "epoch": 0.4581551618814905,
      "grad_norm": 1.969059705734253,
      "learning_rate": 0.00016947668499287313,
      "loss": 0.4213,
      "step": 1500
    },
    {
      "epoch": 0.47342700061087356,
      "grad_norm": 1.4881248474121094,
      "learning_rate": 0.0001684585624109143,
      "loss": 0.4282,
      "step": 1550
    },
    {
      "epoch": 0.48869883934025654,
      "grad_norm": 1.8762707710266113,
      "learning_rate": 0.0001674404398289554,
      "loss": 0.4235,
      "step": 1600
    },
    {
      "epoch": 0.5039706780696396,
      "grad_norm": 1.3152368068695068,
      "learning_rate": 0.00016642231724699655,
      "loss": 0.4167,
      "step": 1650
    },
    {
      "epoch": 0.5192425167990226,
      "grad_norm": 1.4593299627304077,
      "learning_rate": 0.00016540419466503766,
      "loss": 0.4376,
      "step": 1700
    },
    {
      "epoch": 0.5345143555284056,
      "grad_norm": 2.72627329826355,
      "learning_rate": 0.00016438607208307883,
      "loss": 0.4044,
      "step": 1750
    },
    {
      "epoch": 0.5497861942577886,
      "grad_norm": 2.6975197792053223,
      "learning_rate": 0.00016336794950111994,
      "loss": 0.4363,
      "step": 1800
    },
    {
      "epoch": 0.5650580329871716,
      "grad_norm": 1.422565221786499,
      "learning_rate": 0.00016234982691916108,
      "loss": 0.3777,
      "step": 1850
    },
    {
      "epoch": 0.5803298717165547,
      "grad_norm": 2.1792185306549072,
      "learning_rate": 0.00016133170433720221,
      "loss": 0.4238,
      "step": 1900
    },
    {
      "epoch": 0.5956017104459377,
      "grad_norm": 1.3835854530334473,
      "learning_rate": 0.00016031358175524332,
      "loss": 0.4124,
      "step": 1950
    },
    {
      "epoch": 0.6108735491753207,
      "grad_norm": 2.580300807952881,
      "learning_rate": 0.0001592954591732845,
      "loss": 0.4191,
      "step": 2000
    },
    {
      "epoch": 0.6261453879047038,
      "grad_norm": 5.031009674072266,
      "learning_rate": 0.0001582773365913256,
      "loss": 0.4073,
      "step": 2050
    },
    {
      "epoch": 0.6414172266340867,
      "grad_norm": 2.231494426727295,
      "learning_rate": 0.00015725921400936674,
      "loss": 0.4264,
      "step": 2100
    },
    {
      "epoch": 0.6566890653634697,
      "grad_norm": 1.4453444480895996,
      "learning_rate": 0.00015624109142740785,
      "loss": 0.4296,
      "step": 2150
    },
    {
      "epoch": 0.6719609040928528,
      "grad_norm": 3.492774486541748,
      "learning_rate": 0.000155222968845449,
      "loss": 0.4268,
      "step": 2200
    },
    {
      "epoch": 0.6872327428222358,
      "grad_norm": 4.013773441314697,
      "learning_rate": 0.00015420484626349013,
      "loss": 0.3898,
      "step": 2250
    },
    {
      "epoch": 0.7025045815516188,
      "grad_norm": 1.739259123802185,
      "learning_rate": 0.00015318672368153127,
      "loss": 0.4162,
      "step": 2300
    },
    {
      "epoch": 0.7177764202810019,
      "grad_norm": 1.74978506565094,
      "learning_rate": 0.0001521686010995724,
      "loss": 0.421,
      "step": 2350
    },
    {
      "epoch": 0.7330482590103848,
      "grad_norm": 2.8505733013153076,
      "learning_rate": 0.00015115047851761351,
      "loss": 0.3804,
      "step": 2400
    },
    {
      "epoch": 0.7483200977397678,
      "grad_norm": 1.2441720962524414,
      "learning_rate": 0.00015013235593565468,
      "loss": 0.4119,
      "step": 2450
    },
    {
      "epoch": 0.7635919364691509,
      "grad_norm": 1.5879263877868652,
      "learning_rate": 0.0001491142333536958,
      "loss": 0.4104,
      "step": 2500
    },
    {
      "epoch": 0.7788637751985339,
      "grad_norm": 1.4375265836715698,
      "learning_rate": 0.00014809611077173693,
      "loss": 0.4097,
      "step": 2550
    },
    {
      "epoch": 0.7941356139279169,
      "grad_norm": 1.1512938737869263,
      "learning_rate": 0.00014707798818977804,
      "loss": 0.3894,
      "step": 2600
    },
    {
      "epoch": 0.8094074526573,
      "grad_norm": 2.0902302265167236,
      "learning_rate": 0.00014605986560781918,
      "loss": 0.3842,
      "step": 2650
    },
    {
      "epoch": 0.8246792913866829,
      "grad_norm": 1.617728352546692,
      "learning_rate": 0.00014504174302586032,
      "loss": 0.3987,
      "step": 2700
    },
    {
      "epoch": 0.8399511301160659,
      "grad_norm": 3.2106270790100098,
      "learning_rate": 0.00014402362044390146,
      "loss": 0.3836,
      "step": 2750
    },
    {
      "epoch": 0.855222968845449,
      "grad_norm": 1.0714902877807617,
      "learning_rate": 0.0001430054978619426,
      "loss": 0.3905,
      "step": 2800
    },
    {
      "epoch": 0.870494807574832,
      "grad_norm": 2.3384363651275635,
      "learning_rate": 0.0001419873752799837,
      "loss": 0.41,
      "step": 2850
    },
    {
      "epoch": 0.885766646304215,
      "grad_norm": 2.3358657360076904,
      "learning_rate": 0.00014096925269802484,
      "loss": 0.3634,
      "step": 2900
    },
    {
      "epoch": 0.9010384850335981,
      "grad_norm": 1.5790001153945923,
      "learning_rate": 0.00013995113011606598,
      "loss": 0.4015,
      "step": 2950
    },
    {
      "epoch": 0.916310323762981,
      "grad_norm": 1.5820289850234985,
      "learning_rate": 0.00013893300753410712,
      "loss": 0.3965,
      "step": 3000
    },
    {
      "epoch": 0.931582162492364,
      "grad_norm": 3.0644896030426025,
      "learning_rate": 0.00013791488495214823,
      "loss": 0.4225,
      "step": 3050
    },
    {
      "epoch": 0.9468540012217471,
      "grad_norm": 1.7156442403793335,
      "learning_rate": 0.00013689676237018937,
      "loss": 0.394,
      "step": 3100
    },
    {
      "epoch": 0.9621258399511301,
      "grad_norm": 1.7581384181976318,
      "learning_rate": 0.0001358786397882305,
      "loss": 0.3964,
      "step": 3150
    },
    {
      "epoch": 0.9773976786805131,
      "grad_norm": 2.335814952850342,
      "learning_rate": 0.00013486051720627165,
      "loss": 0.391,
      "step": 3200
    },
    {
      "epoch": 0.9926695174098962,
      "grad_norm": 1.1342920064926147,
      "learning_rate": 0.00013384239462431278,
      "loss": 0.4073,
      "step": 3250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8535603148453231,
      "eval_loss": 0.3440394699573517,
      "eval_runtime": 20.3433,
      "eval_samples_per_second": 268.54,
      "eval_steps_per_second": 33.574,
      "step": 3274
    }
  ],
  "logging_steps": 50,
  "max_steps": 9822,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2725725638256432.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
