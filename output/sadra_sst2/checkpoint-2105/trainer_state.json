{
  "best_global_step": 2105,
  "best_metric": 0.27537932991981506,
  "best_model_checkpoint": "./output/sadra_sst2\\checkpoint-2105",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2105,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 2.271364450454712,
      "learning_rate": 0.0001984481393507522,
      "loss": 0.5183,
      "step": 50
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 2.3131985664367676,
      "learning_rate": 0.0001968646080760095,
      "loss": 0.3406,
      "step": 100
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 1.7815885543823242,
      "learning_rate": 0.00019528107680126685,
      "loss": 0.3039,
      "step": 150
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 1.798572063446045,
      "learning_rate": 0.00019369754552652415,
      "loss": 0.3212,
      "step": 200
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 1.675437331199646,
      "learning_rate": 0.0001921140142517815,
      "loss": 0.3245,
      "step": 250
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.7058520317077637,
      "learning_rate": 0.00019053048297703882,
      "loss": 0.3221,
      "step": 300
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.251790761947632,
      "learning_rate": 0.00018894695170229613,
      "loss": 0.2811,
      "step": 350
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 2.2996671199798584,
      "learning_rate": 0.00018736342042755346,
      "loss": 0.2868,
      "step": 400
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 1.0771684646606445,
      "learning_rate": 0.00018577988915281077,
      "loss": 0.3083,
      "step": 450
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 2.850287914276123,
      "learning_rate": 0.0001841963578780681,
      "loss": 0.2754,
      "step": 500
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 1.4178029298782349,
      "learning_rate": 0.0001826128266033254,
      "loss": 0.2693,
      "step": 550
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 1.9095152616500854,
      "learning_rate": 0.00018102929532858275,
      "loss": 0.2469,
      "step": 600
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 1.3433773517608643,
      "learning_rate": 0.00017944576405384008,
      "loss": 0.2699,
      "step": 650
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.187302827835083,
      "learning_rate": 0.0001778622327790974,
      "loss": 0.2483,
      "step": 700
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 1.0236425399780273,
      "learning_rate": 0.00017627870150435472,
      "loss": 0.2568,
      "step": 750
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 0.8820785284042358,
      "learning_rate": 0.00017469517022961203,
      "loss": 0.2498,
      "step": 800
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 2.9853315353393555,
      "learning_rate": 0.00017311163895486936,
      "loss": 0.2606,
      "step": 850
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 1.4495060443878174,
      "learning_rate": 0.00017152810768012667,
      "loss": 0.2374,
      "step": 900
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 0.7432799339294434,
      "learning_rate": 0.000169944576405384,
      "loss": 0.2532,
      "step": 950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 1.231197476387024,
      "learning_rate": 0.00016836104513064134,
      "loss": 0.2604,
      "step": 1000
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 0.9191499352455139,
      "learning_rate": 0.00016677751385589865,
      "loss": 0.2606,
      "step": 1050
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 1.6393862962722778,
      "learning_rate": 0.00016519398258115598,
      "loss": 0.2374,
      "step": 1100
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 0.9168753027915955,
      "learning_rate": 0.00016361045130641332,
      "loss": 0.2169,
      "step": 1150
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 2.0743846893310547,
      "learning_rate": 0.00016202692003167065,
      "loss": 0.2234,
      "step": 1200
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 2.1894099712371826,
      "learning_rate": 0.00016044338875692796,
      "loss": 0.2301,
      "step": 1250
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 0.9270132780075073,
      "learning_rate": 0.0001588598574821853,
      "loss": 0.2442,
      "step": 1300
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 1.746709942817688,
      "learning_rate": 0.00015727632620744263,
      "loss": 0.2393,
      "step": 1350
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 1.6382406949996948,
      "learning_rate": 0.00015569279493269993,
      "loss": 0.2281,
      "step": 1400
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 1.805483102798462,
      "learning_rate": 0.00015410926365795727,
      "loss": 0.2312,
      "step": 1450
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.938569188117981,
      "learning_rate": 0.00015252573238321457,
      "loss": 0.2344,
      "step": 1500
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 1.6202093362808228,
      "learning_rate": 0.0001509422011084719,
      "loss": 0.2338,
      "step": 1550
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.3535635471343994,
      "learning_rate": 0.00014935866983372922,
      "loss": 0.239,
      "step": 1600
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 2.531109571456909,
      "learning_rate": 0.00014777513855898655,
      "loss": 0.2082,
      "step": 1650
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 1.639559268951416,
      "learning_rate": 0.00014619160728424388,
      "loss": 0.2374,
      "step": 1700
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 2.7805047035217285,
      "learning_rate": 0.0001446080760095012,
      "loss": 0.2229,
      "step": 1750
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 1.6350868940353394,
      "learning_rate": 0.00014302454473475853,
      "loss": 0.2335,
      "step": 1800
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 3.4184820652008057,
      "learning_rate": 0.00014144101346001583,
      "loss": 0.2232,
      "step": 1850
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.1599607467651367,
      "learning_rate": 0.00013985748218527317,
      "loss": 0.2166,
      "step": 1900
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 1.253881573677063,
      "learning_rate": 0.00013827395091053048,
      "loss": 0.1846,
      "step": 1950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.7094409465789795,
      "learning_rate": 0.0001366904196357878,
      "loss": 0.2126,
      "step": 2000
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 1.3410433530807495,
      "learning_rate": 0.00013510688836104514,
      "loss": 0.2192,
      "step": 2050
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 1.891147255897522,
      "learning_rate": 0.00013352335708630245,
      "loss": 0.2098,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8967889908256881,
      "eval_loss": 0.27537932991981506,
      "eval_runtime": 2.8234,
      "eval_samples_per_second": 308.85,
      "eval_steps_per_second": 38.606,
      "step": 2105
    }
  ],
  "logging_steps": 50,
  "max_steps": 6315,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 723074552833944.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
