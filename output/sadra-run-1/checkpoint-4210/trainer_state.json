{
  "best_global_step": 2105,
  "best_metric": 0.27574893832206726,
  "best_model_checkpoint": "./output/sadra-run-1\\checkpoint-2105",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 4210,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 3.2874064445495605,
      "learning_rate": 0.0001984481393507522,
      "loss": 0.5176,
      "step": 50
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 2.881282329559326,
      "learning_rate": 0.0001968646080760095,
      "loss": 0.3448,
      "step": 100
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.764308452606201,
      "learning_rate": 0.00019528107680126685,
      "loss": 0.3017,
      "step": 150
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 1.9490255117416382,
      "learning_rate": 0.00019369754552652415,
      "loss": 0.3246,
      "step": 200
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.3735644817352295,
      "learning_rate": 0.0001921140142517815,
      "loss": 0.3244,
      "step": 250
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 2.094292163848877,
      "learning_rate": 0.00019053048297703882,
      "loss": 0.321,
      "step": 300
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.847780227661133,
      "learning_rate": 0.00018894695170229613,
      "loss": 0.2825,
      "step": 350
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 3.029184103012085,
      "learning_rate": 0.00018736342042755346,
      "loss": 0.288,
      "step": 400
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 1.6772956848144531,
      "learning_rate": 0.00018577988915281077,
      "loss": 0.3079,
      "step": 450
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 3.659270763397217,
      "learning_rate": 0.0001841963578780681,
      "loss": 0.28,
      "step": 500
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 2.3677070140838623,
      "learning_rate": 0.0001826128266033254,
      "loss": 0.2715,
      "step": 550
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 2.361189842224121,
      "learning_rate": 0.00018102929532858275,
      "loss": 0.251,
      "step": 600
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 2.07446026802063,
      "learning_rate": 0.00017944576405384008,
      "loss": 0.2668,
      "step": 650
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.215317964553833,
      "learning_rate": 0.0001778622327790974,
      "loss": 0.252,
      "step": 700
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 1.60727059841156,
      "learning_rate": 0.00017627870150435472,
      "loss": 0.2604,
      "step": 750
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 1.1749480962753296,
      "learning_rate": 0.00017469517022961203,
      "loss": 0.2504,
      "step": 800
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 3.9551777839660645,
      "learning_rate": 0.00017311163895486936,
      "loss": 0.2622,
      "step": 850
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 1.8100144863128662,
      "learning_rate": 0.00017152810768012667,
      "loss": 0.2415,
      "step": 900
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 1.131374478340149,
      "learning_rate": 0.000169944576405384,
      "loss": 0.2553,
      "step": 950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 1.3836252689361572,
      "learning_rate": 0.00016836104513064134,
      "loss": 0.2676,
      "step": 1000
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 1.3979904651641846,
      "learning_rate": 0.00016677751385589865,
      "loss": 0.2691,
      "step": 1050
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 1.9963983297348022,
      "learning_rate": 0.00016519398258115598,
      "loss": 0.2358,
      "step": 1100
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 1.2690578699111938,
      "learning_rate": 0.00016361045130641332,
      "loss": 0.2121,
      "step": 1150
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 2.7073311805725098,
      "learning_rate": 0.00016202692003167065,
      "loss": 0.2236,
      "step": 1200
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 3.4665114879608154,
      "learning_rate": 0.00016044338875692796,
      "loss": 0.23,
      "step": 1250
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 1.506273627281189,
      "learning_rate": 0.0001588598574821853,
      "loss": 0.247,
      "step": 1300
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 2.1872479915618896,
      "learning_rate": 0.00015727632620744263,
      "loss": 0.2421,
      "step": 1350
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 2.2274668216705322,
      "learning_rate": 0.00015569279493269993,
      "loss": 0.2353,
      "step": 1400
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 2.4487359523773193,
      "learning_rate": 0.00015410926365795727,
      "loss": 0.2319,
      "step": 1450
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 2.263612747192383,
      "learning_rate": 0.00015252573238321457,
      "loss": 0.2404,
      "step": 1500
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 1.7290921211242676,
      "learning_rate": 0.0001509422011084719,
      "loss": 0.2366,
      "step": 1550
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.6871269941329956,
      "learning_rate": 0.00014935866983372922,
      "loss": 0.2437,
      "step": 1600
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 3.1298060417175293,
      "learning_rate": 0.00014777513855898655,
      "loss": 0.2055,
      "step": 1650
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 2.2471046447753906,
      "learning_rate": 0.00014619160728424388,
      "loss": 0.2363,
      "step": 1700
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 4.250872611999512,
      "learning_rate": 0.0001446080760095012,
      "loss": 0.2274,
      "step": 1750
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.375276803970337,
      "learning_rate": 0.00014302454473475853,
      "loss": 0.2377,
      "step": 1800
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 5.114622116088867,
      "learning_rate": 0.00014144101346001583,
      "loss": 0.2244,
      "step": 1850
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.44476580619812,
      "learning_rate": 0.00013985748218527317,
      "loss": 0.2176,
      "step": 1900
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 1.8776899576187134,
      "learning_rate": 0.00013827395091053048,
      "loss": 0.1857,
      "step": 1950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 2.1561059951782227,
      "learning_rate": 0.0001366904196357878,
      "loss": 0.2181,
      "step": 2000
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 1.6641836166381836,
      "learning_rate": 0.00013510688836104514,
      "loss": 0.209,
      "step": 2050
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 1.9092686176300049,
      "learning_rate": 0.00013352335708630245,
      "loss": 0.2173,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8899082568807339,
      "eval_loss": 0.27574893832206726,
      "eval_runtime": 1.7408,
      "eval_samples_per_second": 500.917,
      "eval_steps_per_second": 16.085,
      "step": 2105
    },
    {
      "epoch": 1.0213776722090262,
      "grad_norm": 3.359431266784668,
      "learning_rate": 0.00013193982581155979,
      "loss": 0.1953,
      "step": 2150
    },
    {
      "epoch": 1.0451306413301662,
      "grad_norm": 3.0359318256378174,
      "learning_rate": 0.0001303562945368171,
      "loss": 0.2046,
      "step": 2200
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 1.2083863019943237,
      "learning_rate": 0.00012877276326207443,
      "loss": 0.1777,
      "step": 2250
    },
    {
      "epoch": 1.0926365795724466,
      "grad_norm": 3.874814510345459,
      "learning_rate": 0.00012718923198733173,
      "loss": 0.2054,
      "step": 2300
    },
    {
      "epoch": 1.1163895486935866,
      "grad_norm": 4.525241851806641,
      "learning_rate": 0.00012560570071258907,
      "loss": 0.1718,
      "step": 2350
    },
    {
      "epoch": 1.1401425178147269,
      "grad_norm": 1.0202652215957642,
      "learning_rate": 0.0001240221694378464,
      "loss": 0.2045,
      "step": 2400
    },
    {
      "epoch": 1.1638954869358669,
      "grad_norm": 2.0705337524414062,
      "learning_rate": 0.00012243863816310374,
      "loss": 0.2015,
      "step": 2450
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.725877046585083,
      "learning_rate": 0.00012085510688836106,
      "loss": 0.1761,
      "step": 2500
    },
    {
      "epoch": 1.2114014251781473,
      "grad_norm": 1.405515432357788,
      "learning_rate": 0.00011927157561361836,
      "loss": 0.1944,
      "step": 2550
    },
    {
      "epoch": 1.2351543942992875,
      "grad_norm": 1.3018120527267456,
      "learning_rate": 0.0001176880443388757,
      "loss": 0.1864,
      "step": 2600
    },
    {
      "epoch": 1.2589073634204275,
      "grad_norm": 2.668994188308716,
      "learning_rate": 0.00011610451306413302,
      "loss": 0.1854,
      "step": 2650
    },
    {
      "epoch": 1.2826603325415677,
      "grad_norm": 1.724882960319519,
      "learning_rate": 0.00011452098178939034,
      "loss": 0.1774,
      "step": 2700
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 2.09773325920105,
      "learning_rate": 0.00011293745051464768,
      "loss": 0.1724,
      "step": 2750
    },
    {
      "epoch": 1.330166270783848,
      "grad_norm": 2.773716926574707,
      "learning_rate": 0.000111353919239905,
      "loss": 0.175,
      "step": 2800
    },
    {
      "epoch": 1.3539192399049882,
      "grad_norm": 2.0350852012634277,
      "learning_rate": 0.00010977038796516233,
      "loss": 0.1782,
      "step": 2850
    },
    {
      "epoch": 1.3776722090261282,
      "grad_norm": 1.8350366353988647,
      "learning_rate": 0.00010818685669041964,
      "loss": 0.166,
      "step": 2900
    },
    {
      "epoch": 1.4014251781472684,
      "grad_norm": 1.4528834819793701,
      "learning_rate": 0.00010660332541567697,
      "loss": 0.1616,
      "step": 2950
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 4.717459678649902,
      "learning_rate": 0.00010501979414093428,
      "loss": 0.1777,
      "step": 3000
    },
    {
      "epoch": 1.4489311163895486,
      "grad_norm": 1.7517412900924683,
      "learning_rate": 0.00010343626286619161,
      "loss": 0.1762,
      "step": 3050
    },
    {
      "epoch": 1.4726840855106889,
      "grad_norm": 4.905501365661621,
      "learning_rate": 0.00010185273159144895,
      "loss": 0.1754,
      "step": 3100
    },
    {
      "epoch": 1.496437054631829,
      "grad_norm": 2.9995992183685303,
      "learning_rate": 0.00010026920031670625,
      "loss": 0.1822,
      "step": 3150
    },
    {
      "epoch": 1.520190023752969,
      "grad_norm": 4.2315473556518555,
      "learning_rate": 9.868566904196358e-05,
      "loss": 0.172,
      "step": 3200
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 3.8868167400360107,
      "learning_rate": 9.71021377672209e-05,
      "loss": 0.1875,
      "step": 3250
    },
    {
      "epoch": 1.5676959619952493,
      "grad_norm": 3.1530251502990723,
      "learning_rate": 9.551860649247823e-05,
      "loss": 0.1514,
      "step": 3300
    },
    {
      "epoch": 1.5914489311163895,
      "grad_norm": 0.9839023947715759,
      "learning_rate": 9.393507521773555e-05,
      "loss": 0.1664,
      "step": 3350
    },
    {
      "epoch": 1.6152019002375297,
      "grad_norm": 3.4289488792419434,
      "learning_rate": 9.235154394299289e-05,
      "loss": 0.1841,
      "step": 3400
    },
    {
      "epoch": 1.63895486935867,
      "grad_norm": 2.757382869720459,
      "learning_rate": 9.07680126682502e-05,
      "loss": 0.1642,
      "step": 3450
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 2.3095450401306152,
      "learning_rate": 8.918448139350753e-05,
      "loss": 0.1732,
      "step": 3500
    },
    {
      "epoch": 1.68646080760095,
      "grad_norm": 3.7844135761260986,
      "learning_rate": 8.760095011876485e-05,
      "loss": 0.1335,
      "step": 3550
    },
    {
      "epoch": 1.7102137767220902,
      "grad_norm": 2.300013780593872,
      "learning_rate": 8.601741884402217e-05,
      "loss": 0.1773,
      "step": 3600
    },
    {
      "epoch": 1.7339667458432304,
      "grad_norm": 4.12655782699585,
      "learning_rate": 8.44338875692795e-05,
      "loss": 0.18,
      "step": 3650
    },
    {
      "epoch": 1.7577197149643706,
      "grad_norm": 2.844477891921997,
      "learning_rate": 8.285035629453682e-05,
      "loss": 0.1524,
      "step": 3700
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 2.6088294982910156,
      "learning_rate": 8.126682501979414e-05,
      "loss": 0.1813,
      "step": 3750
    },
    {
      "epoch": 1.8052256532066508,
      "grad_norm": 2.7619705200195312,
      "learning_rate": 7.968329374505147e-05,
      "loss": 0.1638,
      "step": 3800
    },
    {
      "epoch": 1.8289786223277908,
      "grad_norm": 3.7302465438842773,
      "learning_rate": 7.809976247030879e-05,
      "loss": 0.1749,
      "step": 3850
    },
    {
      "epoch": 1.852731591448931,
      "grad_norm": 0.6850448250770569,
      "learning_rate": 7.651623119556611e-05,
      "loss": 0.1668,
      "step": 3900
    },
    {
      "epoch": 1.8764845605700713,
      "grad_norm": 1.5979909896850586,
      "learning_rate": 7.493269992082344e-05,
      "loss": 0.1498,
      "step": 3950
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 2.9667863845825195,
      "learning_rate": 7.334916864608076e-05,
      "loss": 0.1677,
      "step": 4000
    },
    {
      "epoch": 1.9239904988123515,
      "grad_norm": 2.7486746311187744,
      "learning_rate": 7.17656373713381e-05,
      "loss": 0.205,
      "step": 4050
    },
    {
      "epoch": 1.9477434679334917,
      "grad_norm": 3.0708653926849365,
      "learning_rate": 7.018210609659542e-05,
      "loss": 0.1678,
      "step": 4100
    },
    {
      "epoch": 1.9714964370546317,
      "grad_norm": 2.550229549407959,
      "learning_rate": 6.859857482185274e-05,
      "loss": 0.1629,
      "step": 4150
    },
    {
      "epoch": 1.995249406175772,
      "grad_norm": 1.5204323530197144,
      "learning_rate": 6.701504354711006e-05,
      "loss": 0.1497,
      "step": 4200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8956422018348624,
      "eval_loss": 0.3175637722015381,
      "eval_runtime": 1.7691,
      "eval_samples_per_second": 492.918,
      "eval_steps_per_second": 15.828,
      "step": 4210
    }
  ],
  "logging_steps": 50,
  "max_steps": 6315,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1445954924388288.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
