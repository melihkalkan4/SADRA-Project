{
  "best_global_step": 2105,
  "best_metric": 0.27574893832206726,
  "best_model_checkpoint": "./output/sadra-run-1\\checkpoint-2105",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2105,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 3.2874064445495605,
      "learning_rate": 0.0001984481393507522,
      "loss": 0.5176,
      "step": 50
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 2.881282329559326,
      "learning_rate": 0.0001968646080760095,
      "loss": 0.3448,
      "step": 100
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.764308452606201,
      "learning_rate": 0.00019528107680126685,
      "loss": 0.3017,
      "step": 150
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 1.9490255117416382,
      "learning_rate": 0.00019369754552652415,
      "loss": 0.3246,
      "step": 200
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.3735644817352295,
      "learning_rate": 0.0001921140142517815,
      "loss": 0.3244,
      "step": 250
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 2.094292163848877,
      "learning_rate": 0.00019053048297703882,
      "loss": 0.321,
      "step": 300
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.847780227661133,
      "learning_rate": 0.00018894695170229613,
      "loss": 0.2825,
      "step": 350
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 3.029184103012085,
      "learning_rate": 0.00018736342042755346,
      "loss": 0.288,
      "step": 400
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 1.6772956848144531,
      "learning_rate": 0.00018577988915281077,
      "loss": 0.3079,
      "step": 450
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 3.659270763397217,
      "learning_rate": 0.0001841963578780681,
      "loss": 0.28,
      "step": 500
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 2.3677070140838623,
      "learning_rate": 0.0001826128266033254,
      "loss": 0.2715,
      "step": 550
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 2.361189842224121,
      "learning_rate": 0.00018102929532858275,
      "loss": 0.251,
      "step": 600
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 2.07446026802063,
      "learning_rate": 0.00017944576405384008,
      "loss": 0.2668,
      "step": 650
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.215317964553833,
      "learning_rate": 0.0001778622327790974,
      "loss": 0.252,
      "step": 700
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 1.60727059841156,
      "learning_rate": 0.00017627870150435472,
      "loss": 0.2604,
      "step": 750
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 1.1749480962753296,
      "learning_rate": 0.00017469517022961203,
      "loss": 0.2504,
      "step": 800
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 3.9551777839660645,
      "learning_rate": 0.00017311163895486936,
      "loss": 0.2622,
      "step": 850
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 1.8100144863128662,
      "learning_rate": 0.00017152810768012667,
      "loss": 0.2415,
      "step": 900
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 1.131374478340149,
      "learning_rate": 0.000169944576405384,
      "loss": 0.2553,
      "step": 950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 1.3836252689361572,
      "learning_rate": 0.00016836104513064134,
      "loss": 0.2676,
      "step": 1000
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 1.3979904651641846,
      "learning_rate": 0.00016677751385589865,
      "loss": 0.2691,
      "step": 1050
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 1.9963983297348022,
      "learning_rate": 0.00016519398258115598,
      "loss": 0.2358,
      "step": 1100
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 1.2690578699111938,
      "learning_rate": 0.00016361045130641332,
      "loss": 0.2121,
      "step": 1150
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 2.7073311805725098,
      "learning_rate": 0.00016202692003167065,
      "loss": 0.2236,
      "step": 1200
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 3.4665114879608154,
      "learning_rate": 0.00016044338875692796,
      "loss": 0.23,
      "step": 1250
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 1.506273627281189,
      "learning_rate": 0.0001588598574821853,
      "loss": 0.247,
      "step": 1300
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 2.1872479915618896,
      "learning_rate": 0.00015727632620744263,
      "loss": 0.2421,
      "step": 1350
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 2.2274668216705322,
      "learning_rate": 0.00015569279493269993,
      "loss": 0.2353,
      "step": 1400
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 2.4487359523773193,
      "learning_rate": 0.00015410926365795727,
      "loss": 0.2319,
      "step": 1450
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 2.263612747192383,
      "learning_rate": 0.00015252573238321457,
      "loss": 0.2404,
      "step": 1500
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 1.7290921211242676,
      "learning_rate": 0.0001509422011084719,
      "loss": 0.2366,
      "step": 1550
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.6871269941329956,
      "learning_rate": 0.00014935866983372922,
      "loss": 0.2437,
      "step": 1600
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 3.1298060417175293,
      "learning_rate": 0.00014777513855898655,
      "loss": 0.2055,
      "step": 1650
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 2.2471046447753906,
      "learning_rate": 0.00014619160728424388,
      "loss": 0.2363,
      "step": 1700
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 4.250872611999512,
      "learning_rate": 0.0001446080760095012,
      "loss": 0.2274,
      "step": 1750
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.375276803970337,
      "learning_rate": 0.00014302454473475853,
      "loss": 0.2377,
      "step": 1800
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 5.114622116088867,
      "learning_rate": 0.00014144101346001583,
      "loss": 0.2244,
      "step": 1850
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.44476580619812,
      "learning_rate": 0.00013985748218527317,
      "loss": 0.2176,
      "step": 1900
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 1.8776899576187134,
      "learning_rate": 0.00013827395091053048,
      "loss": 0.1857,
      "step": 1950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 2.1561059951782227,
      "learning_rate": 0.0001366904196357878,
      "loss": 0.2181,
      "step": 2000
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 1.6641836166381836,
      "learning_rate": 0.00013510688836104514,
      "loss": 0.209,
      "step": 2050
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 1.9092686176300049,
      "learning_rate": 0.00013352335708630245,
      "loss": 0.2173,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8899082568807339,
      "eval_loss": 0.27574893832206726,
      "eval_runtime": 1.7408,
      "eval_samples_per_second": 500.917,
      "eval_steps_per_second": 16.085,
      "step": 2105
    }
  ],
  "logging_steps": 50,
  "max_steps": 6315,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 722276388546456.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
