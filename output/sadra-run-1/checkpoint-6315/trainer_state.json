{
  "best_global_step": 2105,
  "best_metric": 0.27574893832206726,
  "best_model_checkpoint": "./output/sadra-run-1\\checkpoint-2105",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 6315,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 3.2874064445495605,
      "learning_rate": 0.0001984481393507522,
      "loss": 0.5176,
      "step": 50
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 2.881282329559326,
      "learning_rate": 0.0001968646080760095,
      "loss": 0.3448,
      "step": 100
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.764308452606201,
      "learning_rate": 0.00019528107680126685,
      "loss": 0.3017,
      "step": 150
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 1.9490255117416382,
      "learning_rate": 0.00019369754552652415,
      "loss": 0.3246,
      "step": 200
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.3735644817352295,
      "learning_rate": 0.0001921140142517815,
      "loss": 0.3244,
      "step": 250
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 2.094292163848877,
      "learning_rate": 0.00019053048297703882,
      "loss": 0.321,
      "step": 300
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.847780227661133,
      "learning_rate": 0.00018894695170229613,
      "loss": 0.2825,
      "step": 350
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 3.029184103012085,
      "learning_rate": 0.00018736342042755346,
      "loss": 0.288,
      "step": 400
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 1.6772956848144531,
      "learning_rate": 0.00018577988915281077,
      "loss": 0.3079,
      "step": 450
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 3.659270763397217,
      "learning_rate": 0.0001841963578780681,
      "loss": 0.28,
      "step": 500
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 2.3677070140838623,
      "learning_rate": 0.0001826128266033254,
      "loss": 0.2715,
      "step": 550
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 2.361189842224121,
      "learning_rate": 0.00018102929532858275,
      "loss": 0.251,
      "step": 600
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 2.07446026802063,
      "learning_rate": 0.00017944576405384008,
      "loss": 0.2668,
      "step": 650
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.215317964553833,
      "learning_rate": 0.0001778622327790974,
      "loss": 0.252,
      "step": 700
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 1.60727059841156,
      "learning_rate": 0.00017627870150435472,
      "loss": 0.2604,
      "step": 750
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 1.1749480962753296,
      "learning_rate": 0.00017469517022961203,
      "loss": 0.2504,
      "step": 800
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 3.9551777839660645,
      "learning_rate": 0.00017311163895486936,
      "loss": 0.2622,
      "step": 850
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 1.8100144863128662,
      "learning_rate": 0.00017152810768012667,
      "loss": 0.2415,
      "step": 900
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 1.131374478340149,
      "learning_rate": 0.000169944576405384,
      "loss": 0.2553,
      "step": 950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 1.3836252689361572,
      "learning_rate": 0.00016836104513064134,
      "loss": 0.2676,
      "step": 1000
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 1.3979904651641846,
      "learning_rate": 0.00016677751385589865,
      "loss": 0.2691,
      "step": 1050
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 1.9963983297348022,
      "learning_rate": 0.00016519398258115598,
      "loss": 0.2358,
      "step": 1100
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 1.2690578699111938,
      "learning_rate": 0.00016361045130641332,
      "loss": 0.2121,
      "step": 1150
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 2.7073311805725098,
      "learning_rate": 0.00016202692003167065,
      "loss": 0.2236,
      "step": 1200
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 3.4665114879608154,
      "learning_rate": 0.00016044338875692796,
      "loss": 0.23,
      "step": 1250
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 1.506273627281189,
      "learning_rate": 0.0001588598574821853,
      "loss": 0.247,
      "step": 1300
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 2.1872479915618896,
      "learning_rate": 0.00015727632620744263,
      "loss": 0.2421,
      "step": 1350
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 2.2274668216705322,
      "learning_rate": 0.00015569279493269993,
      "loss": 0.2353,
      "step": 1400
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 2.4487359523773193,
      "learning_rate": 0.00015410926365795727,
      "loss": 0.2319,
      "step": 1450
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 2.263612747192383,
      "learning_rate": 0.00015252573238321457,
      "loss": 0.2404,
      "step": 1500
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 1.7290921211242676,
      "learning_rate": 0.0001509422011084719,
      "loss": 0.2366,
      "step": 1550
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.6871269941329956,
      "learning_rate": 0.00014935866983372922,
      "loss": 0.2437,
      "step": 1600
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 3.1298060417175293,
      "learning_rate": 0.00014777513855898655,
      "loss": 0.2055,
      "step": 1650
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 2.2471046447753906,
      "learning_rate": 0.00014619160728424388,
      "loss": 0.2363,
      "step": 1700
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 4.250872611999512,
      "learning_rate": 0.0001446080760095012,
      "loss": 0.2274,
      "step": 1750
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.375276803970337,
      "learning_rate": 0.00014302454473475853,
      "loss": 0.2377,
      "step": 1800
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 5.114622116088867,
      "learning_rate": 0.00014144101346001583,
      "loss": 0.2244,
      "step": 1850
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.44476580619812,
      "learning_rate": 0.00013985748218527317,
      "loss": 0.2176,
      "step": 1900
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 1.8776899576187134,
      "learning_rate": 0.00013827395091053048,
      "loss": 0.1857,
      "step": 1950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 2.1561059951782227,
      "learning_rate": 0.0001366904196357878,
      "loss": 0.2181,
      "step": 2000
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 1.6641836166381836,
      "learning_rate": 0.00013510688836104514,
      "loss": 0.209,
      "step": 2050
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 1.9092686176300049,
      "learning_rate": 0.00013352335708630245,
      "loss": 0.2173,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8899082568807339,
      "eval_loss": 0.27574893832206726,
      "eval_runtime": 1.7408,
      "eval_samples_per_second": 500.917,
      "eval_steps_per_second": 16.085,
      "step": 2105
    },
    {
      "epoch": 1.0213776722090262,
      "grad_norm": 3.359431266784668,
      "learning_rate": 0.00013193982581155979,
      "loss": 0.1953,
      "step": 2150
    },
    {
      "epoch": 1.0451306413301662,
      "grad_norm": 3.0359318256378174,
      "learning_rate": 0.0001303562945368171,
      "loss": 0.2046,
      "step": 2200
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 1.2083863019943237,
      "learning_rate": 0.00012877276326207443,
      "loss": 0.1777,
      "step": 2250
    },
    {
      "epoch": 1.0926365795724466,
      "grad_norm": 3.874814510345459,
      "learning_rate": 0.00012718923198733173,
      "loss": 0.2054,
      "step": 2300
    },
    {
      "epoch": 1.1163895486935866,
      "grad_norm": 4.525241851806641,
      "learning_rate": 0.00012560570071258907,
      "loss": 0.1718,
      "step": 2350
    },
    {
      "epoch": 1.1401425178147269,
      "grad_norm": 1.0202652215957642,
      "learning_rate": 0.0001240221694378464,
      "loss": 0.2045,
      "step": 2400
    },
    {
      "epoch": 1.1638954869358669,
      "grad_norm": 2.0705337524414062,
      "learning_rate": 0.00012243863816310374,
      "loss": 0.2015,
      "step": 2450
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.725877046585083,
      "learning_rate": 0.00012085510688836106,
      "loss": 0.1761,
      "step": 2500
    },
    {
      "epoch": 1.2114014251781473,
      "grad_norm": 1.405515432357788,
      "learning_rate": 0.00011927157561361836,
      "loss": 0.1944,
      "step": 2550
    },
    {
      "epoch": 1.2351543942992875,
      "grad_norm": 1.3018120527267456,
      "learning_rate": 0.0001176880443388757,
      "loss": 0.1864,
      "step": 2600
    },
    {
      "epoch": 1.2589073634204275,
      "grad_norm": 2.668994188308716,
      "learning_rate": 0.00011610451306413302,
      "loss": 0.1854,
      "step": 2650
    },
    {
      "epoch": 1.2826603325415677,
      "grad_norm": 1.724882960319519,
      "learning_rate": 0.00011452098178939034,
      "loss": 0.1774,
      "step": 2700
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 2.09773325920105,
      "learning_rate": 0.00011293745051464768,
      "loss": 0.1724,
      "step": 2750
    },
    {
      "epoch": 1.330166270783848,
      "grad_norm": 2.773716926574707,
      "learning_rate": 0.000111353919239905,
      "loss": 0.175,
      "step": 2800
    },
    {
      "epoch": 1.3539192399049882,
      "grad_norm": 2.0350852012634277,
      "learning_rate": 0.00010977038796516233,
      "loss": 0.1782,
      "step": 2850
    },
    {
      "epoch": 1.3776722090261282,
      "grad_norm": 1.8350366353988647,
      "learning_rate": 0.00010818685669041964,
      "loss": 0.166,
      "step": 2900
    },
    {
      "epoch": 1.4014251781472684,
      "grad_norm": 1.4528834819793701,
      "learning_rate": 0.00010660332541567697,
      "loss": 0.1616,
      "step": 2950
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 4.717459678649902,
      "learning_rate": 0.00010501979414093428,
      "loss": 0.1777,
      "step": 3000
    },
    {
      "epoch": 1.4489311163895486,
      "grad_norm": 1.7517412900924683,
      "learning_rate": 0.00010343626286619161,
      "loss": 0.1762,
      "step": 3050
    },
    {
      "epoch": 1.4726840855106889,
      "grad_norm": 4.905501365661621,
      "learning_rate": 0.00010185273159144895,
      "loss": 0.1754,
      "step": 3100
    },
    {
      "epoch": 1.496437054631829,
      "grad_norm": 2.9995992183685303,
      "learning_rate": 0.00010026920031670625,
      "loss": 0.1822,
      "step": 3150
    },
    {
      "epoch": 1.520190023752969,
      "grad_norm": 4.2315473556518555,
      "learning_rate": 9.868566904196358e-05,
      "loss": 0.172,
      "step": 3200
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 3.8868167400360107,
      "learning_rate": 9.71021377672209e-05,
      "loss": 0.1875,
      "step": 3250
    },
    {
      "epoch": 1.5676959619952493,
      "grad_norm": 3.1530251502990723,
      "learning_rate": 9.551860649247823e-05,
      "loss": 0.1514,
      "step": 3300
    },
    {
      "epoch": 1.5914489311163895,
      "grad_norm": 0.9839023947715759,
      "learning_rate": 9.393507521773555e-05,
      "loss": 0.1664,
      "step": 3350
    },
    {
      "epoch": 1.6152019002375297,
      "grad_norm": 3.4289488792419434,
      "learning_rate": 9.235154394299289e-05,
      "loss": 0.1841,
      "step": 3400
    },
    {
      "epoch": 1.63895486935867,
      "grad_norm": 2.757382869720459,
      "learning_rate": 9.07680126682502e-05,
      "loss": 0.1642,
      "step": 3450
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 2.3095450401306152,
      "learning_rate": 8.918448139350753e-05,
      "loss": 0.1732,
      "step": 3500
    },
    {
      "epoch": 1.68646080760095,
      "grad_norm": 3.7844135761260986,
      "learning_rate": 8.760095011876485e-05,
      "loss": 0.1335,
      "step": 3550
    },
    {
      "epoch": 1.7102137767220902,
      "grad_norm": 2.300013780593872,
      "learning_rate": 8.601741884402217e-05,
      "loss": 0.1773,
      "step": 3600
    },
    {
      "epoch": 1.7339667458432304,
      "grad_norm": 4.12655782699585,
      "learning_rate": 8.44338875692795e-05,
      "loss": 0.18,
      "step": 3650
    },
    {
      "epoch": 1.7577197149643706,
      "grad_norm": 2.844477891921997,
      "learning_rate": 8.285035629453682e-05,
      "loss": 0.1524,
      "step": 3700
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 2.6088294982910156,
      "learning_rate": 8.126682501979414e-05,
      "loss": 0.1813,
      "step": 3750
    },
    {
      "epoch": 1.8052256532066508,
      "grad_norm": 2.7619705200195312,
      "learning_rate": 7.968329374505147e-05,
      "loss": 0.1638,
      "step": 3800
    },
    {
      "epoch": 1.8289786223277908,
      "grad_norm": 3.7302465438842773,
      "learning_rate": 7.809976247030879e-05,
      "loss": 0.1749,
      "step": 3850
    },
    {
      "epoch": 1.852731591448931,
      "grad_norm": 0.6850448250770569,
      "learning_rate": 7.651623119556611e-05,
      "loss": 0.1668,
      "step": 3900
    },
    {
      "epoch": 1.8764845605700713,
      "grad_norm": 1.5979909896850586,
      "learning_rate": 7.493269992082344e-05,
      "loss": 0.1498,
      "step": 3950
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 2.9667863845825195,
      "learning_rate": 7.334916864608076e-05,
      "loss": 0.1677,
      "step": 4000
    },
    {
      "epoch": 1.9239904988123515,
      "grad_norm": 2.7486746311187744,
      "learning_rate": 7.17656373713381e-05,
      "loss": 0.205,
      "step": 4050
    },
    {
      "epoch": 1.9477434679334917,
      "grad_norm": 3.0708653926849365,
      "learning_rate": 7.018210609659542e-05,
      "loss": 0.1678,
      "step": 4100
    },
    {
      "epoch": 1.9714964370546317,
      "grad_norm": 2.550229549407959,
      "learning_rate": 6.859857482185274e-05,
      "loss": 0.1629,
      "step": 4150
    },
    {
      "epoch": 1.995249406175772,
      "grad_norm": 1.5204323530197144,
      "learning_rate": 6.701504354711006e-05,
      "loss": 0.1497,
      "step": 4200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8956422018348624,
      "eval_loss": 0.3175637722015381,
      "eval_runtime": 1.7691,
      "eval_samples_per_second": 492.918,
      "eval_steps_per_second": 15.828,
      "step": 4210
    },
    {
      "epoch": 2.019002375296912,
      "grad_norm": 3.151716470718384,
      "learning_rate": 6.543151227236738e-05,
      "loss": 0.1453,
      "step": 4250
    },
    {
      "epoch": 2.0427553444180524,
      "grad_norm": 7.840513229370117,
      "learning_rate": 6.38479809976247e-05,
      "loss": 0.1654,
      "step": 4300
    },
    {
      "epoch": 2.0665083135391926,
      "grad_norm": 3.636342763900757,
      "learning_rate": 6.226444972288203e-05,
      "loss": 0.1257,
      "step": 4350
    },
    {
      "epoch": 2.0902612826603324,
      "grad_norm": 2.1971001625061035,
      "learning_rate": 6.0680918448139355e-05,
      "loss": 0.1638,
      "step": 4400
    },
    {
      "epoch": 2.1140142517814726,
      "grad_norm": 1.9509097337722778,
      "learning_rate": 5.9097387173396676e-05,
      "loss": 0.1369,
      "step": 4450
    },
    {
      "epoch": 2.137767220902613,
      "grad_norm": 0.45535123348236084,
      "learning_rate": 5.7513855898654e-05,
      "loss": 0.1578,
      "step": 4500
    },
    {
      "epoch": 2.161520190023753,
      "grad_norm": 1.6742991209030151,
      "learning_rate": 5.5930324623911324e-05,
      "loss": 0.1485,
      "step": 4550
    },
    {
      "epoch": 2.1852731591448933,
      "grad_norm": 2.5869462490081787,
      "learning_rate": 5.4346793349168645e-05,
      "loss": 0.1779,
      "step": 4600
    },
    {
      "epoch": 2.209026128266033,
      "grad_norm": 4.783236026763916,
      "learning_rate": 5.2763262074425966e-05,
      "loss": 0.1454,
      "step": 4650
    },
    {
      "epoch": 2.2327790973871733,
      "grad_norm": 3.064950466156006,
      "learning_rate": 5.11797307996833e-05,
      "loss": 0.127,
      "step": 4700
    },
    {
      "epoch": 2.2565320665083135,
      "grad_norm": 4.436760902404785,
      "learning_rate": 4.959619952494062e-05,
      "loss": 0.1377,
      "step": 4750
    },
    {
      "epoch": 2.2802850356294537,
      "grad_norm": 5.115495204925537,
      "learning_rate": 4.801266825019795e-05,
      "loss": 0.1447,
      "step": 4800
    },
    {
      "epoch": 2.304038004750594,
      "grad_norm": 3.2536494731903076,
      "learning_rate": 4.642913697545527e-05,
      "loss": 0.1423,
      "step": 4850
    },
    {
      "epoch": 2.3277909738717337,
      "grad_norm": 4.193536281585693,
      "learning_rate": 4.484560570071259e-05,
      "loss": 0.1448,
      "step": 4900
    },
    {
      "epoch": 2.351543942992874,
      "grad_norm": 3.3968632221221924,
      "learning_rate": 4.326207442596992e-05,
      "loss": 0.1344,
      "step": 4950
    },
    {
      "epoch": 2.375296912114014,
      "grad_norm": 3.005401611328125,
      "learning_rate": 4.167854315122724e-05,
      "loss": 0.1596,
      "step": 5000
    },
    {
      "epoch": 2.3990498812351544,
      "grad_norm": 2.753068685531616,
      "learning_rate": 4.009501187648456e-05,
      "loss": 0.1442,
      "step": 5050
    },
    {
      "epoch": 2.4228028503562946,
      "grad_norm": 3.602968215942383,
      "learning_rate": 3.8511480601741886e-05,
      "loss": 0.1473,
      "step": 5100
    },
    {
      "epoch": 2.446555819477435,
      "grad_norm": 3.824368715286255,
      "learning_rate": 3.6927949326999214e-05,
      "loss": 0.1494,
      "step": 5150
    },
    {
      "epoch": 2.470308788598575,
      "grad_norm": 1.4654268026351929,
      "learning_rate": 3.5344418052256535e-05,
      "loss": 0.1214,
      "step": 5200
    },
    {
      "epoch": 2.494061757719715,
      "grad_norm": 4.411464691162109,
      "learning_rate": 3.3760886777513855e-05,
      "loss": 0.1266,
      "step": 5250
    },
    {
      "epoch": 2.517814726840855,
      "grad_norm": 1.3868142366409302,
      "learning_rate": 3.217735550277118e-05,
      "loss": 0.135,
      "step": 5300
    },
    {
      "epoch": 2.5415676959619953,
      "grad_norm": 1.7434717416763306,
      "learning_rate": 3.0593824228028504e-05,
      "loss": 0.1526,
      "step": 5350
    },
    {
      "epoch": 2.5653206650831355,
      "grad_norm": 3.671523332595825,
      "learning_rate": 2.9010292953285828e-05,
      "loss": 0.1385,
      "step": 5400
    },
    {
      "epoch": 2.5890736342042757,
      "grad_norm": 2.9615018367767334,
      "learning_rate": 2.742676167854315e-05,
      "loss": 0.1531,
      "step": 5450
    },
    {
      "epoch": 2.6128266033254155,
      "grad_norm": 8.209832191467285,
      "learning_rate": 2.584323040380048e-05,
      "loss": 0.1317,
      "step": 5500
    },
    {
      "epoch": 2.6365795724465557,
      "grad_norm": 1.053936243057251,
      "learning_rate": 2.42596991290578e-05,
      "loss": 0.1423,
      "step": 5550
    },
    {
      "epoch": 2.660332541567696,
      "grad_norm": 1.4940402507781982,
      "learning_rate": 2.2676167854315125e-05,
      "loss": 0.1592,
      "step": 5600
    },
    {
      "epoch": 2.684085510688836,
      "grad_norm": 4.333154678344727,
      "learning_rate": 2.109263657957245e-05,
      "loss": 0.1302,
      "step": 5650
    },
    {
      "epoch": 2.7078384798099764,
      "grad_norm": 8.230622291564941,
      "learning_rate": 1.9509105304829773e-05,
      "loss": 0.135,
      "step": 5700
    },
    {
      "epoch": 2.731591448931116,
      "grad_norm": 5.702639579772949,
      "learning_rate": 1.7925574030087094e-05,
      "loss": 0.1307,
      "step": 5750
    },
    {
      "epoch": 2.7553444180522564,
      "grad_norm": 1.3681074380874634,
      "learning_rate": 1.6342042755344418e-05,
      "loss": 0.1542,
      "step": 5800
    },
    {
      "epoch": 2.7790973871733966,
      "grad_norm": 5.94835090637207,
      "learning_rate": 1.4758511480601742e-05,
      "loss": 0.1406,
      "step": 5850
    },
    {
      "epoch": 2.802850356294537,
      "grad_norm": 2.998161792755127,
      "learning_rate": 1.3174980205859066e-05,
      "loss": 0.1323,
      "step": 5900
    },
    {
      "epoch": 2.826603325415677,
      "grad_norm": 3.304718017578125,
      "learning_rate": 1.159144893111639e-05,
      "loss": 0.1364,
      "step": 5950
    },
    {
      "epoch": 2.850356294536817,
      "grad_norm": 6.656939506530762,
      "learning_rate": 1.0007917656373714e-05,
      "loss": 0.1494,
      "step": 6000
    },
    {
      "epoch": 2.8741092636579575,
      "grad_norm": 1.594406247138977,
      "learning_rate": 8.424386381631037e-06,
      "loss": 0.1193,
      "step": 6050
    },
    {
      "epoch": 2.8978622327790973,
      "grad_norm": 2.3395538330078125,
      "learning_rate": 6.840855106888361e-06,
      "loss": 0.1432,
      "step": 6100
    },
    {
      "epoch": 2.9216152019002375,
      "grad_norm": 2.5516326427459717,
      "learning_rate": 5.257323832145685e-06,
      "loss": 0.1254,
      "step": 6150
    },
    {
      "epoch": 2.9453681710213777,
      "grad_norm": 3.5637242794036865,
      "learning_rate": 3.673792557403009e-06,
      "loss": 0.1359,
      "step": 6200
    },
    {
      "epoch": 2.969121140142518,
      "grad_norm": 4.815254211425781,
      "learning_rate": 2.0902612826603326e-06,
      "loss": 0.1334,
      "step": 6250
    },
    {
      "epoch": 2.992874109263658,
      "grad_norm": 3.1531338691711426,
      "learning_rate": 5.067300079176564e-07,
      "loss": 0.1545,
      "step": 6300
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8990825688073395,
      "eval_loss": 0.34491002559661865,
      "eval_runtime": 1.6009,
      "eval_samples_per_second": 544.709,
      "eval_steps_per_second": 17.491,
      "step": 6315
    }
  ],
  "logging_steps": 50,
  "max_steps": 6315,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2169018052604856.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
