import torch
from peft import get_peft_model, LoraConfig, TaskType

def apply_sadra_to_model(model, rank_config, default_rank=8, alpha_ratio=2.0):
    """
    SADRA (Sensitivity-Aware Dynamic Rank Allocation) motoru.
    
    Bu fonksiyon, hesaplanan hassasiyet skorlarÄ±na gÃ¶re her katmana 
    farklÄ± Rank (r) atayarak PEFT modelini oluÅŸturur.
    
    Args:
        model: HuggingFace Base Model (Pre-trained)
        rank_config: {layer_name: int_rank} sÃ¶zlÃ¼ÄŸÃ¼ (Manager'dan gelen)
        default_rank: Config'de olmayan katmanlar iÃ§in varsayÄ±lan rank.
        alpha_ratio: LoRA Alpha = Rank * Ratio (Genelde 2x kararlÄ±dÄ±r).
    
    Returns:
        peft_model: EÄŸitime hazÄ±r SADRA modeli.
    """
    print(f"\n[SADRA] Motor BaÅŸlatÄ±lÄ±yor... Hedef Katman SayÄ±sÄ±: {len(rank_config)}")
    
    # 1. Rank Pattern ve Target Modules HazÄ±rlÄ±ÄŸÄ±
    # PEFT kÃ¼tÃ¼phanesi, hangi modÃ¼llere LoRA takÄ±lacaÄŸÄ±nÄ± 'target_modules' listesiyle,
    # hangi katmana kaÃ§ rank verileceÄŸini 'rank_pattern' sÃ¶zlÃ¼ÄŸÃ¼yle anlar.
    
    rank_pattern = {}
    target_suffixes = set()
    
    for name, rank in rank_config.items():
        # Parametre isminden (weight) kurtul, modÃ¼l ismini al
        # Ã–rn: 'distilbert.layer.0.lin1.weight' -> 'distilbert.layer.0.lin1'
        clean_name = name.replace(".weight", "")
        
        # Pattern'e ekle
        rank_pattern[clean_name] = rank
        
        # Soneki (Suffix) bul (lin1, q_lin, query, key, value vb.)
        # PEFT'in 'target_modules' parametresi iÃ§in gereklidir.
        suffix = clean_name.split(".")[-1]
        target_suffixes.add(suffix)

    print(f"[SADRA] Tespit Edilen ModÃ¼l Tipleri: {list(target_suffixes)}")
    
    # 2. Dinamik KonfigÃ¼rasyonun OluÅŸturulmasÄ±
    peft_config = LoraConfig(
        task_type=TaskType.SEQ_CLS, # SÄ±nÄ±flandÄ±rma gÃ¶revi (Modeline gÃ¶re deÄŸiÅŸebilir)
        inference_mode=False,
        r=default_rank,             # VarsayÄ±lan (Fallback) deÄŸer
        lora_alpha=default_rank * alpha_ratio, # Alpha genelde rank'Ä±n 2 katÄ±dÄ±r
        lora_dropout=0.1,
        target_modules=list(target_suffixes), # ['q_lin', 'lin1'...]
        rank_pattern=rank_pattern   # <--- Ä°ÅTE SADRA BURADA DEVREYE GÄ°RÄ°YOR
    )
    
    # 3. Modelin DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi
    try:
        peft_model = get_peft_model(model, peft_config)
        
        # BaÅŸarÄ± Ä°statistiÄŸi
        trainable_params, all_params = peft_model.get_nb_trainable_parameters()
        print(f"[SADRA] Model HazÄ±r! ğŸš€")
        print(f" -> EÄŸitilebilir Parametre: {trainable_params:,}")
        print(f" -> Oran: %{100 * trainable_params / all_params:.2f}")
        
        return peft_model
        
    except Exception as e:
        print(f"[SADRA ERROR] Model dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼rken kritik hata: {e}")
        raise e