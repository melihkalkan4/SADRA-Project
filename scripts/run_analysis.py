import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding
from datasets import load_dataset
from torch.utils.data import DataLoader
from sadra.core import estimate_hessian_trace
import sys

# Cihaz seÃ§imi (GPU varsa kullan, yoksa CPU)
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"SADRA Analysis Script baÅŸlatÄ±lÄ±yor... Cihaz: {device.upper()}")

# 1. MODEL VE TOKENIZER HAZIRLIÄI
# HÄ±zlÄ± sonuÃ§ almak iÃ§in 'distilbert' kullanÄ±yoruz. 
# GerÃ§ek makalede 'roberta-large' veya 'llama-3' kullanacaÄŸÄ±z.
model_id = "distilbert-base-uncased"
print(f"Model indiriliyor: {model_id}...")

try:
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForSequenceClassification.from_pretrained(model_id).to(device)
except Exception as e:
    print(f"Hata: Model indirilemedi. Ä°nternet baÄŸlantÄ±nÄ± kontrol et.\nDetay: {e}")
    sys.exit(1)

# 2. VERÄ° SETÄ° HAZIRLIÄI (GLUE / SST-2)
print("Veri seti indiriliyor (GLUE/SST-2)...")
raw_datasets = load_dataset("glue", "sst2", split="train[:100]") # Sadece ilk 100 Ã¶rnek (HÄ±z iÃ§in)

def tokenize_function(examples):
    return tokenizer(examples["sentence"], truncation=True, padding=False)

tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
tokenized_datasets = tokenized_datasets.remove_columns(["sentence", "idx"])
tokenized_datasets = tokenized_datasets.rename_column("label", "labels")
tokenized_datasets.set_format("torch")

# Data Collator (Batch'leri aynÄ± boyuta getirmek iÃ§in)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
train_dataloader = DataLoader(
    tokenized_datasets, 
    shuffle=True, 
    batch_size=8, 
    collate_fn=data_collator
)

# 3. SADRA ANALÄ°ZÄ° (Hessian Trace Estimation)
print("\n--- SADRA: Katman DuyarlÄ±lÄ±k Analizi BaÅŸlÄ±yor ---")
#'core.py' fonksiyonunu Ã§aÄŸÄ±rÄ±yoruz:
scores = estimate_hessian_trace(
    model=model,
    data_loader=train_dataloader,
    device=device,
    num_batches=5,  # 5 batch (40 Ã¶rnek) Ã¼zerinden hesapla
    num_vectors=10  # Her parametre iÃ§in 10 rastgele vektÃ¶r
)

# 4. SONUÃ‡LARI GÃ–RSELLEÅTÄ°RME
print("\n--- SONUÃ‡LAR: En DuyarlÄ± 10 Katman ---")
# Skorlara gÃ¶re bÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe sÄ±rala
sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)

for name, score in sorted_scores[:10]:
    print(f"Layer: {name:<50} | Sensitivity (Trace): {score:.4f}")

print("\nAnaliz BaÅŸarÄ±yla TamamlandÄ±! ğŸš€")